{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp-starter.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cvm82yKXnXW_"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3xb-E8SniCa",
        "outputId": "d0f28025-3492-4f98-b9ab-a03d1e9962b8"
      },
      "source": [
        "print(nltk.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwvsBentoSZs"
      },
      "source": [
        "Convert to Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN5AJqFonmRb",
        "outputId": "782a7a92-5789-44e2-ee4f-2fec8d960764"
      },
      "source": [
        "#nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgV8websntYI"
      },
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb1EJMghn15-",
        "outputId": "e5e07362-421d-41de-947d-07784d39e6f3"
      },
      "source": [
        "print(word_tokenize(\"You should visit Malawi sometime,it's a beautiful country.\"))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['You', 'should', 'visit', 'Malawi', 'sometime', ',', 'it', \"'s\", 'a', 'beautiful', 'country', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z5fPCJRoWHQ"
      },
      "source": [
        "Convert to base forms \n",
        "\n",
        "1. Stemming \n",
        "2. Lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpACBnW-pRII"
      },
      "source": [
        "Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yL5YqL-oZB-",
        "outputId": "d8b1d82e-c00f-45b3-d8bd-e5bd033514e8"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer \n",
        "stemmer = PorterStemmer()\n",
        "print(stemmer.stem(\"going\"))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "go\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyGAU1SDpAgt",
        "outputId": "2355e240-4b7f-45e8-d34a-bc960b2cc2f3"
      },
      "source": [
        "#weakness of stemming\n",
        "print(stemmer.stem(\"constitutes\"))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "constitut\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAoKT2BBpb5V"
      },
      "source": [
        "Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw4Wo5YXpfJZ",
        "outputId": "1456af07-14f4-4b2e-e507-0377cef59685"
      },
      "source": [
        "#nltk.download('wordnet')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKVIzOE9plo9"
      },
      "source": [
        "from nltk.stem.wordnet import WordNetLemmatizer \n",
        "lem = WordNetLemmatizer()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLBupiStp1nx",
        "outputId": "76a64c8d-5de1-4769-aa8e-37a139ec7612"
      },
      "source": [
        "#corectly gives base word\n",
        "print(lem.lemmatize('constitutes', 'v'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "constitute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-ZarmXSqOZe",
        "outputId": "8aca901e-c00a-47c6-fcba-c4247da658b0"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDzqZ5udqZxE",
        "outputId": "cf80c6aa-07a0-423c-ac8f-3baebc94a627"
      },
      "source": [
        "from nltk.tag import pos_tag\n",
        "sample = \"Hi, this is a nice hotel.\"\n",
        "print(pos_tag(word_tokenize(sample)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Hi', 'NNP'), (',', ','), ('this', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('nice', 'JJ'), ('hotel', 'NN'), ('.', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XukpdTRPr2R0",
        "outputId": "9aee4345-ec35-426e-c4fd-799845c43afc"
      },
      "source": [
        "def lemmatize_tokens(stentence):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  lemmatized_tokens = []\n",
        "  for word, tag in pos_tag(stentence):\n",
        "    if tag.startswith('NN'):\n",
        "      pos = 'n'\n",
        "    elif tag.startswith('VB'):\n",
        "      pos = 'v'\n",
        "    else:\n",
        "      pos = 'a'\n",
        "    lemmatized_tokens.append(lemmatizer.lemmatize(word, pos))\n",
        "  return lemmatized_tokens\n",
        "\n",
        "sample = \"Legal authority constitutes all magistrates.\"\n",
        "print(lemmatize_tokens(word_tokenize(sample)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Legal', 'authority', 'constitute', 'all', 'magistrate', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ9aFr7Ls5Xn"
      },
      "source": [
        "Data cleaning \n",
        "1. Remove punctuation\n",
        "2. Reomove Stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqfBINMGthcF"
      },
      "source": [
        "Remove punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tViSDvLEs-yf",
        "outputId": "ebab7ad6-602c-4229-82ee-43b5363a7c73"
      },
      "source": [
        "import string\n",
        "print(string.punctuation)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "her8QaIKtUfO"
      },
      "source": [
        "for token in tokens:\n",
        "  if token in string.punctuation:\n",
        "    # Do something"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}